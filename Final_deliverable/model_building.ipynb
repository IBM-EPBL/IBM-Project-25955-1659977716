{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8a73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa566f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e80424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n",
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(\n",
    "    r'/home/sibi-joshva/Documents/Final_deliverable/Final code/Dataset/TRAIN_SET',target_size=(64,64),batch_size=5,color_mode='rgb',class_mode='sparse'\n",
    ")\n",
    "\n",
    "x_test=test_datagen.flow_from_directory(\n",
    "    r'/home/sibi-joshva/Documents/Final_deliverable/Final code/Dataset/TRAIN_SET',target_size=(64,64),batch_size=5,color_mode='rgb',class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f92f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLE': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
      "{'APPLE': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)\n",
    "\n",
    "print(x_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf49435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 10, 1: 10, 2: 10, 3: 10, 4: 10})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train .labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2f4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999cf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa439ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7c049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 23s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911a8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39ac655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe17ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 12:39:08.097157: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5119 - accuracy: 0.4478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 12:39:25.825959: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 122880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.5119 - accuracy: 0.4478 - val_loss: 1.2970 - val_accuracy: 0.5473\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1821 - accuracy: 0.5796 - val_loss: 1.1222 - val_accuracy: 0.6068\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0302 - accuracy: 0.6379 - val_loss: 1.0108 - val_accuracy: 0.6505\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9227 - accuracy: 0.6771 - val_loss: 0.9277 - val_accuracy: 0.6743\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8510 - accuracy: 0.7008 - val_loss: 0.8977 - val_accuracy: 0.6872\n"
     ]
    }
   ],
   "source": [
    "#Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "#Fitting the model\n",
    "history = model.fit(train_images, train_labels, epochs=5, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c762ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d42be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,733\n",
      "Trainable params: 813,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=5, activation='softmax'))\n",
    "#summary of our model\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b596ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving our model\n",
    "model.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4894011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# categorical_crossentropy for more than 2\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06bb2a77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18151/191451636.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(generator=x_train,steps_per_epoch = len(x_train),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Fitting the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \n\u001b[1;32m   2497\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2505\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2506\u001b[0m )\n\u001b[0;32m-> 2507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/preprocessing/image.py:2529\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.apply_affine_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_affine_transform\u001b[39m(\n\u001b[1;32m   2487\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2499\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   2500\u001b[0m ):\n\u001b[1;32m   2501\u001b[0m     \u001b[38;5;124;03m\"\"\"Applies an affine transformation specified by the parameters given.\u001b[39;00m\n\u001b[1;32m   2502\u001b[0m \n\u001b[1;32m   2503\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \u001b[38;5;124;03m        ImportError: if SciPy is not available.\u001b[39;00m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscipy\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2530\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2531\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage transformations require SciPy. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall SciPy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2532\u001b[0m         )\n\u001b[1;32m   2534\u001b[0m     \u001b[38;5;66;03m# Input sanity checks:\u001b[39;00m\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;66;03m# 1. x must 2D image with one or more channels (i.e., a 3D tensor)\u001b[39;00m\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;66;03m# 2. channels must be either first or last dimension\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "#Fitting the model\n",
    "classifier.fit_generator(generator=x_train,steps_per_epoch = len(x_train),\n",
    "    epochs=20,validation_data=x_test,validation_steps = len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61bef53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ceb6c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediciting our results\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model=load_model('nutrition.h5')\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "#loading of the image\n",
    "img = image.load_img('/home/sibi-joshva/Documents/Final_deliverable/Final code/Dataset/TEST_SET/APPLE/49_100.jpg',grayscale=False,target_size= (64,64))\n",
    "#image to array\n",
    "x = img_to_array(img)\n",
    "#changing the shape\n",
    "x = np.expand_dims(x,axis = 0)\n",
    "predict_x=model.predict(x) \n",
    "classes_x=np.argmax(predict_x,axis=-1)\n",
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4bc89d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70 at 0x7FB434574820>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img('/home/sibi-joshva/Documents/Final_deliverable/Final code/Dataset/TEST_SET/APPLE/49_100.jpg',\n",
    "                   target_size=(70,70))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4006d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d543130e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]]]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61401785",
   "metadata": {},
   "source": [
    "x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07c78e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a752720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bac1225b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9972819e-16, 2.9768269e-16, 1.0000000e+00, 5.5895168e-32,\n",
       "        9.2532284e-36]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adcf515f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APPLES'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['APPLES', 'BANANA', 'ORANGE', 'PINEAPPLE', 'WATERMELON']\n",
    "result=str(index[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71db1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
